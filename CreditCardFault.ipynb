{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e95bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem Statement\n",
    "#The goal of the project is to detect whether a transaction is a normal payment or a fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42b7a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc750a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv files with pandas\n",
    "fraud_data = read_csv('C:\\\\Users\\\\Dayanand\\\\Desktop\\\\SamatrixDataScience\\\\Machine Learning Projects\\\\Project 1(Finance)\\\\DataSets\\\\creditcard.csv.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86904cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7        V8        V9  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599  0.098698  0.363787   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803  0.085102 -0.255425   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461  0.247676 -1.514654   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609  0.377436 -1.387024   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941 -0.270533  0.817739   \n",
       "\n",
       "   ...       V21       V22       V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0  ... -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "\n",
       "   Class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the raw data\n",
    "set_option('display.width', 100)\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de82954c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dimension of the data\n",
    "fraud_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78c4a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "#The Data Types of the attributes\n",
    "fraud_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fab56dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count of Null Values\n",
    "fraud_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b9d3e0",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c83d7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.00</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>2.85e+05</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>2.85e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.86</td>\n",
       "      <td>3.92e-15</td>\n",
       "      <td>5.68e-16</td>\n",
       "      <td>-8.76e-15</td>\n",
       "      <td>2.81e-15</td>\n",
       "      <td>-1.55e-15</td>\n",
       "      <td>2.04e-15</td>\n",
       "      <td>-1.70e-15</td>\n",
       "      <td>-1.89e-16</td>\n",
       "      <td>-3.15e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47e-16</td>\n",
       "      <td>8.04e-16</td>\n",
       "      <td>5.28e-16</td>\n",
       "      <td>4.46e-15</td>\n",
       "      <td>1.43e-15</td>\n",
       "      <td>1.70e-15</td>\n",
       "      <td>-3.66e-16</td>\n",
       "      <td>-1.22e-16</td>\n",
       "      <td>88.35</td>\n",
       "      <td>1.73e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.15</td>\n",
       "      <td>1.96e+00</td>\n",
       "      <td>1.65e+00</td>\n",
       "      <td>1.52e+00</td>\n",
       "      <td>1.42e+00</td>\n",
       "      <td>1.38e+00</td>\n",
       "      <td>1.33e+00</td>\n",
       "      <td>1.24e+00</td>\n",
       "      <td>1.19e+00</td>\n",
       "      <td>1.10e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.35e-01</td>\n",
       "      <td>7.26e-01</td>\n",
       "      <td>6.24e-01</td>\n",
       "      <td>6.06e-01</td>\n",
       "      <td>5.21e-01</td>\n",
       "      <td>4.82e-01</td>\n",
       "      <td>4.04e-01</td>\n",
       "      <td>3.30e-01</td>\n",
       "      <td>250.12</td>\n",
       "      <td>4.15e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.64e+01</td>\n",
       "      <td>-7.27e+01</td>\n",
       "      <td>-4.83e+01</td>\n",
       "      <td>-5.68e+00</td>\n",
       "      <td>-1.14e+02</td>\n",
       "      <td>-2.62e+01</td>\n",
       "      <td>-4.36e+01</td>\n",
       "      <td>-7.32e+01</td>\n",
       "      <td>-1.34e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.48e+01</td>\n",
       "      <td>-1.09e+01</td>\n",
       "      <td>-4.48e+01</td>\n",
       "      <td>-2.84e+00</td>\n",
       "      <td>-1.03e+01</td>\n",
       "      <td>-2.60e+00</td>\n",
       "      <td>-2.26e+01</td>\n",
       "      <td>-1.54e+01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.50</td>\n",
       "      <td>-9.20e-01</td>\n",
       "      <td>-5.99e-01</td>\n",
       "      <td>-8.90e-01</td>\n",
       "      <td>-8.49e-01</td>\n",
       "      <td>-6.92e-01</td>\n",
       "      <td>-7.68e-01</td>\n",
       "      <td>-5.54e-01</td>\n",
       "      <td>-2.09e-01</td>\n",
       "      <td>-6.43e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.28e-01</td>\n",
       "      <td>-5.42e-01</td>\n",
       "      <td>-1.62e-01</td>\n",
       "      <td>-3.55e-01</td>\n",
       "      <td>-3.17e-01</td>\n",
       "      <td>-3.27e-01</td>\n",
       "      <td>-7.08e-02</td>\n",
       "      <td>-5.30e-02</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.00</td>\n",
       "      <td>1.81e-02</td>\n",
       "      <td>6.55e-02</td>\n",
       "      <td>1.80e-01</td>\n",
       "      <td>-1.98e-02</td>\n",
       "      <td>-5.43e-02</td>\n",
       "      <td>-2.74e-01</td>\n",
       "      <td>4.01e-02</td>\n",
       "      <td>2.24e-02</td>\n",
       "      <td>-5.14e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.95e-02</td>\n",
       "      <td>6.78e-03</td>\n",
       "      <td>-1.12e-02</td>\n",
       "      <td>4.10e-02</td>\n",
       "      <td>1.66e-02</td>\n",
       "      <td>-5.21e-02</td>\n",
       "      <td>1.34e-03</td>\n",
       "      <td>1.12e-02</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.50</td>\n",
       "      <td>1.32e+00</td>\n",
       "      <td>8.04e-01</td>\n",
       "      <td>1.03e+00</td>\n",
       "      <td>7.43e-01</td>\n",
       "      <td>6.12e-01</td>\n",
       "      <td>3.99e-01</td>\n",
       "      <td>5.70e-01</td>\n",
       "      <td>3.27e-01</td>\n",
       "      <td>5.97e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.86e-01</td>\n",
       "      <td>5.29e-01</td>\n",
       "      <td>1.48e-01</td>\n",
       "      <td>4.40e-01</td>\n",
       "      <td>3.51e-01</td>\n",
       "      <td>2.41e-01</td>\n",
       "      <td>9.10e-02</td>\n",
       "      <td>7.83e-02</td>\n",
       "      <td>77.16</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.00</td>\n",
       "      <td>2.45e+00</td>\n",
       "      <td>2.21e+01</td>\n",
       "      <td>9.38e+00</td>\n",
       "      <td>1.69e+01</td>\n",
       "      <td>3.48e+01</td>\n",
       "      <td>7.33e+01</td>\n",
       "      <td>1.21e+02</td>\n",
       "      <td>2.00e+01</td>\n",
       "      <td>1.56e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.72e+01</td>\n",
       "      <td>1.05e+01</td>\n",
       "      <td>2.25e+01</td>\n",
       "      <td>4.58e+00</td>\n",
       "      <td>7.52e+00</td>\n",
       "      <td>3.52e+00</td>\n",
       "      <td>3.16e+01</td>\n",
       "      <td>3.38e+01</td>\n",
       "      <td>25691.16</td>\n",
       "      <td>1.00e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6        V7        V8  \\\n",
       "count  284807.00  2.85e+05  2.85e+05  2.85e+05  2.85e+05  2.85e+05  2.85e+05  2.85e+05  2.85e+05   \n",
       "mean    94813.86  3.92e-15  5.68e-16 -8.76e-15  2.81e-15 -1.55e-15  2.04e-15 -1.70e-15 -1.89e-16   \n",
       "std     47488.15  1.96e+00  1.65e+00  1.52e+00  1.42e+00  1.38e+00  1.33e+00  1.24e+00  1.19e+00   \n",
       "min         0.00 -5.64e+01 -7.27e+01 -4.83e+01 -5.68e+00 -1.14e+02 -2.62e+01 -4.36e+01 -7.32e+01   \n",
       "25%     54201.50 -9.20e-01 -5.99e-01 -8.90e-01 -8.49e-01 -6.92e-01 -7.68e-01 -5.54e-01 -2.09e-01   \n",
       "50%     84692.00  1.81e-02  6.55e-02  1.80e-01 -1.98e-02 -5.43e-02 -2.74e-01  4.01e-02  2.24e-02   \n",
       "75%    139320.50  1.32e+00  8.04e-01  1.03e+00  7.43e-01  6.12e-01  3.99e-01  5.70e-01  3.27e-01   \n",
       "max    172792.00  2.45e+00  2.21e+01  9.38e+00  1.69e+01  3.48e+01  7.33e+01  1.21e+02  2.00e+01   \n",
       "\n",
       "             V9  ...       V21       V22       V23       V24       V25       V26       V27  \\\n",
       "count  2.85e+05  ...  2.85e+05  2.85e+05  2.85e+05  2.85e+05  2.85e+05  2.85e+05  2.85e+05   \n",
       "mean  -3.15e-15  ...  1.47e-16  8.04e-16  5.28e-16  4.46e-15  1.43e-15  1.70e-15 -3.66e-16   \n",
       "std    1.10e+00  ...  7.35e-01  7.26e-01  6.24e-01  6.06e-01  5.21e-01  4.82e-01  4.04e-01   \n",
       "min   -1.34e+01  ... -3.48e+01 -1.09e+01 -4.48e+01 -2.84e+00 -1.03e+01 -2.60e+00 -2.26e+01   \n",
       "25%   -6.43e-01  ... -2.28e-01 -5.42e-01 -1.62e-01 -3.55e-01 -3.17e-01 -3.27e-01 -7.08e-02   \n",
       "50%   -5.14e-02  ... -2.95e-02  6.78e-03 -1.12e-02  4.10e-02  1.66e-02 -5.21e-02  1.34e-03   \n",
       "75%    5.97e-01  ...  1.86e-01  5.29e-01  1.48e-01  4.40e-01  3.51e-01  2.41e-01  9.10e-02   \n",
       "max    1.56e+01  ...  2.72e+01  1.05e+01  2.25e+01  4.58e+00  7.52e+00  3.52e+00  3.16e+01   \n",
       "\n",
       "            V28     Amount     Class  \n",
       "count  2.85e+05  284807.00  2.85e+05  \n",
       "mean  -1.22e-16      88.35  1.73e-03  \n",
       "std    3.30e-01     250.12  4.15e-02  \n",
       "min   -1.54e+01       0.00  0.00e+00  \n",
       "25%   -5.30e-02       5.60  0.00e+00  \n",
       "50%    1.12e-02      22.00  0.00e+00  \n",
       "75%    7.83e-02      77.16  0.00e+00  \n",
       "max    3.38e+01   25691.16  1.00e+00  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Statistical Analysis of data\n",
    "set_option('precision', 2)\n",
    "fraud_data.describe()\n",
    "#fraud_data.describe().T -T-Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f187e517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Fraud    284315\n",
      "Fraud           492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Response Variable Analysis\n",
    "#Fraud vs Non-Fraud\n",
    "class_names = {0:'Not Fraud', 1:'Fraud'}\n",
    "print(fraud_data.Class.value_counts().rename(index = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3715ccb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.Class.value_counts()[0:1]\n",
    "fraud_data.groupby(\"Class\")[\"Class\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "827ecb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94936,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the datasets into train & test\n",
    "from sklearn.model_selection import train_test_split\n",
    "y= fraud_data[\"Class\"]\n",
    "X = fraud_data.loc[:, fraud_data.columns != 'Class']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42, stratify=y)\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400af904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library for Accuracy Score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab6a9d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model :  99.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dayanand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "#Import Library for Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Initialize the Logistic Regression Classifier\n",
    "logisreg = LogisticRegression()\n",
    "\n",
    "#Train the model using Training Dataset\n",
    "logisreg.fit(X_train, y_train)\n",
    "\n",
    "# Prediction using test data\n",
    "y_pred = logisreg.predict(X_test)\n",
    "\n",
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_logisreg = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of Logistic Regression model : ', acc_logisreg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f350a0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Linear Discriminant Analysis Classifier:  99.93\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis\n",
    "#Import Library for Linear Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "#Initialize the LDA Classifier\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_lda = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of Linear Discriminant Analysis Classifier: ', acc_lda )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd9a88d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Naive Bayes :  99.28\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "#Import Library for Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Initialize the Gaussian Naive Bayes Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_ganb = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of Gaussian Naive Bayes : ', acc_ganb )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "042a5a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  Decision Tree Classifier :  99.91\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "#Import Library for Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Initialize the Decision Tree Classifier\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_dtree = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of  Decision Tree Classifier : ', acc_dtree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdeb8411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  Random Forest :  99.95\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "#Import Library for Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Initialize the Random Forest\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_rf = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of  Random Forest : ', acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24ec656e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  Support Vector Classifier:  99.83\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine Model\n",
    "#Import Library for Support Vector Machine Model\n",
    "from sklearn import svm\n",
    "\n",
    "#Initialize the Support Vector Classifier\n",
    "model = svm.SVC()\n",
    "\n",
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_svc = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of  Support Vector Classifier: ', acc_svc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de549085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  KNN Classifier:  99.83\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbour Model\n",
    "#Import Library for K Nearest Neighbour Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Initialize the K Nearest Neighbour Model with Default Value of K=5\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_knn = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of  KNN Classifier: ', acc_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2dace65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>99.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>99.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>99.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>99.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>99.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K - Nearest Neighbors</td>\n",
       "      <td>99.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>99.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Score\n",
       "4                 Random Forest  99.95\n",
       "1  Linear Discriminant Analysis  99.93\n",
       "0           Logistic Regression  99.91\n",
       "3                 Decision Tree  99.91\n",
       "5       Support Vector Machines  99.83\n",
       "6         K - Nearest Neighbors  99.83\n",
       "2                   Naive Bayes  99.28"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Selection\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Linear Discriminant Analysis','Naive Bayes', 'Decision Tree', 'Random Forest', 'Support Vector Machines', \n",
    "              'K - Nearest Neighbors'],\n",
    "    'Score': [acc_logisreg, acc_lda, acc_ganb, acc_dtree, acc_rf, acc_svc, acc_knn]})\n",
    "\n",
    "models.sort_values(by='Score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c604c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94772,     0],\n",
       "       [  164,     0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f1454a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dayanand\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1d484638190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix Graph\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(model, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
